# The Reflective Intelligence (RI) Reasoning Model

The Reflective Intelligence (RI) Reasoning Model represents a paradigm shift in human-AI collaboration—moving beyond traditional AI interactions toward a true cognitive partnership that amplifies human thinking rather than replacing it.

![Sample Image](./images/tmpz1ufukqz.png)

## Overview

The RI Reasoning Model is built on the **'AI as our Inner Voice’** approach, representing how AI interacts with humans by reflecting human cognitive patterns rather than simply providing answers. The model helps you explore problems from multiple dimensions and discover well-rounded solutions. It encourages deeper engagement with your specific context, creating responses that feel more natural and thoughtful.

[Read the full article](https://medium.com/@example_link_here) for a comprehensive exploration.


## Versions

- **[RI-Reasoning-Model-v1.5.0-turivny](./model/RI-Reasoning-Model-v1.5.0-turivny.md)**

  Initial release of the RI Reasoning Model, introducing the core framework for symbiotic human-AI collaboration.

  Core Capabilities:
   - Multidimensional Understanding: The model builds a rich, 3D understanding of each query through interconnected perspectives.
   - Adaptive Reasoning Process: Instead of rushing to the first plausible answer, the model employs an iterative approach inspired by evolutionary processes.
   - Human-Centered Communication: The model dynamically tailors its communication style to match your specific needs.
   - Collaborative Partnership: Rather than positioning itself as an authority, the model functions as a genuine thinking partner.

## FAQ

### How do I get started with the RI Reasoning Model?

Getting started with the RI Reasoning Model is straightforward:

- **Simple integration**: Add the model as a prefix to your prompts with reasoning-capable LLMs (Claude, DeepSeek, Gemini) to transform their responses:

```
Your question here...

<reasoning model>
// Copy the full model here
</reasoning model>
```

### What license governs this project?

This project is released under the **CC BY 4.0 with Ethical Supplement**, which explicitly prohibits military applications and harmful uses while ensuring the technology remains open and accessible.

See the [LICENSE.md](LICENSE.md) file for complete details on permissions and restrictions.

### How can I contribute to the RI Reasoning Model?

Interested in contributing? Check out [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed guidelines on adding your own version of the model.

###   What Principles Underlie the Model?

The RI Reasoning Model is built on three "AI as a Partner" principles:

1. **Critical Thinking Function**: AI should question itself and filter its own informational noise by applying critical thinking to its reasoning process.
   
2. **Cognitive Autonomy**: AI should explain its reasoning and respect users' rights to risk and creative freedom by encouraging independent critical thinking.
   
3. **Proactive Approach**: AI should not blindly obey and ask questions, encouraging users to reason for themselves and protecting them from harmful actions.


### What does the Ethical Supplement mean for this project?

The ethical supplement to license explicitly prohibits:
- Military or weapons-related applications
- Discriminatory systems or mass surveillance
- Implementations that may cause physical or psychological harm

### Can I use the images in this repository, and under what terms?

- All images are © Generated by Yura Turivny. 
- The images in this repository are available for use **within the project** under the **CC BY 4.0** [IMG_LICENSE.md](./images/IMG_LICENSE.md).

### How can I get in touch or join the project?

If you're interested in collaborating or have questions:

- [www.turivny.com](https://www.turivny.com/)
- GitHub Issues: For bug reports and feature discussions

**Join the project!** Whether you're a researcher, developer, or AI enthusiast, there's a place for your perspective in shaping the future of human-AI collaboration. Let's build AI that thinks *with* you, not *for* you.

© Yura Turivny, 2025

